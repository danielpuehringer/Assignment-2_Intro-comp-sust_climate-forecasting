{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-14T13:46:30.845517Z",
     "start_time": "2025-12-14T13:46:30.840747Z"
    }
   },
   "source": "# todo: comment this file",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-14T13:46:30.854452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "LSTM baseline (fixed):\n",
    "- Prevents pandas label-indexing bugs by converting y to NumPy before sequencing\n",
    "- Uses float32 for TF stability/performance\n",
    "- Reports RMSE on the same scale as FFN/WaveNet (no forced inverse_transform)\n",
    "- Optionally also reports/plots in original units if y_scaler is present AND y looks scaled\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "SEED = 42\n",
    "SEQUENCE_LENGTH = 5\n",
    "EPOCHS = 2 #use 20 instead of 2\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "PLOT_LOSS = True\n",
    "PLOT_TEST_PREDICTIONS = True\n",
    "\n",
    "# If you want strictly the same metric style as FFN/WaveNet, keep this True\n",
    "REPORT_RMSE_ON_STORED_SCALE = True\n",
    "\n",
    "# Optional: also report/plot in original units if we can safely inverse-transform\n",
    "REPORT_AND_PLOT_ORIGINAL_UNITS_IF_POSSIBLE = True\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Reproducibility\n",
    "# -----------------------\n",
    "np.random.seed(SEED)\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices(\"GPU\")))\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "def to_numpy_float32(x):\n",
    "    \"\"\"Convert pandas/np to numpy float32.\"\"\"\n",
    "    if hasattr(x, \"to_numpy\"):\n",
    "        return x.to_numpy(dtype=np.float32)\n",
    "    if hasattr(x, \"values\"):\n",
    "        return np.asarray(x.values, dtype=np.float32)\n",
    "    return np.asarray(x, dtype=np.float32)\n",
    "\n",
    "def to_1d_float32(y):\n",
    "    \"\"\"Convert to 1D numpy float32.\"\"\"\n",
    "    y = np.asarray(y, dtype=np.float32)\n",
    "    return y.reshape(-1)\n",
    "\n",
    "def create_sequences(X, y, seq_length):\n",
    "    \"\"\"\n",
    "    X: (n, features)\n",
    "    y: (n,)\n",
    "    returns:\n",
    "      X_seq: (n-seq_length, seq_length, features)\n",
    "      y_seq: (n-seq_length,)\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    y = np.asarray(y, dtype=np.float32).reshape(-1)\n",
    "\n",
    "    if len(X) != len(y):\n",
    "        raise ValueError(f\"X and y length mismatch: len(X)={len(X)} vs len(y)={len(y)}\")\n",
    "    if len(X) <= seq_length:\n",
    "        raise ValueError(f\"Not enough rows to build sequences: len(X)={len(X)} <= seq_length={seq_length}\")\n",
    "\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i : i + seq_length])\n",
    "        y_seq.append(y[i + seq_length])\n",
    "\n",
    "    return np.asarray(X_seq, dtype=np.float32), np.asarray(y_seq, dtype=np.float32)\n",
    "\n",
    "def looks_like_minmax_scaled(y, scaler, tol=1e-3):\n",
    "    \"\"\"\n",
    "    Conservative heuristic: if scaler has feature_range and y lies inside it -> likely scaled.\n",
    "    \"\"\"\n",
    "    if scaler is None or not hasattr(scaler, \"feature_range\"):\n",
    "        return False\n",
    "    lo, hi = scaler.feature_range\n",
    "    y_min, y_max = float(np.min(y)), float(np.max(y))\n",
    "    return (y_min >= lo - tol) and (y_max <= hi + tol)\n",
    "\n",
    "def safe_inverse_transform_1d(y_1d, scaler):\n",
    "    \"\"\"\n",
    "    Inverse-transform a 1D array safely if scaler supports it.\n",
    "    \"\"\"\n",
    "    y_1d = np.asarray(y_1d, dtype=np.float32).reshape(-1, 1)\n",
    "    return scaler.inverse_transform(y_1d).reshape(-1)\n",
    "\n",
    "class TrainRMSECallback(Callback):\n",
    "    \"\"\"\n",
    "    Prints train RMSE (on stored scale) at epoch end.\n",
    "    Note: uses predict() each epoch, can be slow on large datasets.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_train_seq, y_train_seq):\n",
    "        super().__init__()\n",
    "        self.X = X_train_seq\n",
    "        self.y = y_train_seq\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        pred = self.model.predict(self.X, verbose=0).reshape(-1)\n",
    "        rmse = np.sqrt(mean_squared_error(self.y, pred))\n",
    "        print(f\"Epoch {epoch+1:03d} - Train RMSE (stored scale): {rmse:.4f}\")\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Load data\n",
    "# -----------------------\n",
    "with open(\"preprocessed_data.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Convert X to numpy float32\n",
    "X_train = to_numpy_float32(data[\"X_train\"])\n",
    "X_val   = to_numpy_float32(data[\"X_val\"])\n",
    "X_test  = to_numpy_float32(data[\"X_test\"])\n",
    "\n",
    "# Convert y to 1D numpy float32 (FIXES pandas indexing bug)\n",
    "y_train = to_1d_float32(data[\"y_train\"])\n",
    "y_val   = to_1d_float32(data[\"y_val\"])\n",
    "y_test  = to_1d_float32(data[\"y_test\"])\n",
    "\n",
    "# Optional dates\n",
    "test_dates = data.get(\"test_dates\", None)\n",
    "if test_dates is not None:\n",
    "    # keep as array-like for plotting\n",
    "    test_dates = np.asarray(test_dates)\n",
    "\n",
    "# Optional scaler for y\n",
    "y_scaler = data.get(\"scaler_y\", None)\n",
    "\n",
    "print(\"Loaded keys:\", list(data.keys()))\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_val:  \", X_val.shape,   \"y_val:  \", y_val.shape)\n",
    "print(\"X_test: \", X_test.shape,  \"y_test: \", y_test.shape)\n",
    "\n",
    "# -----------------------\n",
    "# Build sequences\n",
    "# -----------------------\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train, SEQUENCE_LENGTH)\n",
    "X_val_seq,   y_val_seq   = create_sequences(X_val,   y_val,   SEQUENCE_LENGTH)\n",
    "X_test_seq,  y_test_seq  = create_sequences(X_test,  y_test,  SEQUENCE_LENGTH)\n",
    "\n",
    "print(\"X_train_seq:\", X_train_seq.shape, \"y_train_seq:\", y_train_seq.shape)\n",
    "print(\"X_val_seq:  \", X_val_seq.shape,   \"y_val_seq:  \", y_val_seq.shape)\n",
    "print(\"X_test_seq: \", X_test_seq.shape,  \"y_test_seq: \", y_test_seq.shape)\n",
    "\n",
    "# -----------------------\n",
    "# Model\n",
    "# -----------------------\n",
    "model = Sequential([\n",
    "    Input(shape=(SEQUENCE_LENGTH, X_train_seq.shape[2])),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64),\n",
    "    Dropout(0.2),\n",
    "    Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"mse\",\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-6),\n",
    "    TrainRMSECallback(X_train_seq, y_train_seq),\n",
    "]\n",
    "\n",
    "# -----------------------\n",
    "# Train\n",
    "# -----------------------\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,   # good for time series\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Plot loss\n",
    "if PLOT_LOSS:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history.history[\"loss\"], label=\"train loss (MSE)\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"val loss (MSE)\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training / Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------\n",
    "# Evaluate\n",
    "# -----------------------\n",
    "pred_scaled = model.predict(X_test_seq, verbose=0).reshape(-1)\n",
    "\n",
    "# RMSE on stored scale (matches FFN/WaveNet scripts)\n",
    "rmse_stored = np.sqrt(mean_squared_error(y_test_seq.reshape(-1), pred_scaled))\n",
    "print(f\"Test RMSE (stored scale): {rmse_stored:.4f}\")\n",
    "\n",
    "# Optional: also compute RMSE in original units if we can safely inverse-transform\n",
    "rmse_original = None\n",
    "actual_for_plot = y_test_seq\n",
    "pred_for_plot = pred_scaled\n",
    "y_axis_label = \"Target (stored scale)\"\n",
    "\n",
    "if (\n",
    "    REPORT_AND_PLOT_ORIGINAL_UNITS_IF_POSSIBLE\n",
    "    and y_scaler is not None\n",
    "    and hasattr(y_scaler, \"inverse_transform\")\n",
    "    and looks_like_minmax_scaled(y_test_seq, y_scaler)\n",
    "):\n",
    "    actual_orig = safe_inverse_transform_1d(y_test_seq, y_scaler)\n",
    "    pred_orig   = safe_inverse_transform_1d(pred_scaled, y_scaler)\n",
    "    rmse_original = np.sqrt(mean_squared_error(actual_orig, pred_orig))\n",
    "    print(f\"Test RMSE (original units): {rmse_original:.4f}\")\n",
    "\n",
    "    actual_for_plot = actual_orig\n",
    "    pred_for_plot = pred_orig\n",
    "    y_axis_label = \"Target (original units)\"\n",
    "else:\n",
    "    if REPORT_AND_PLOT_ORIGINAL_UNITS_IF_POSSIBLE and y_scaler is not None:\n",
    "        print(\"Note: y_scaler exists, but y does not look like MinMax-scaled data -> skipping inverse_transform to avoid wrong numbers.\")\n",
    "\n",
    "# -----------------------\n",
    "# Plot predictions\n",
    "# -----------------------\n",
    "if PLOT_TEST_PREDICTIONS:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    if test_dates is not None and len(test_dates) >= (SEQUENCE_LENGTH + len(actual_for_plot)):\n",
    "        x = test_dates[SEQUENCE_LENGTH : SEQUENCE_LENGTH + len(actual_for_plot)]\n",
    "        plt.plot(x, actual_for_plot, label=\"Actual\")\n",
    "        plt.plot(x, pred_for_plot, label=\"Predicted\")\n",
    "        plt.xlabel(\"Date\")\n",
    "    else:\n",
    "        plt.plot(actual_for_plot, label=\"Actual\")\n",
    "        plt.plot(pred_for_plot, label=\"Predicted\")\n",
    "        plt.xlabel(\"Time step\")\n",
    "\n",
    "    plt.ylabel(y_axis_label)\n",
    "    plt.title(\"LSTM Test: Actual vs Predicted\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "115ebd7d3546061c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n",
      "Loaded keys: ['X_train', 'X_val', 'X_test', 'y_train', 'y_val', 'y_test', 'scaler', 'scaler_y', 'test_dates']\n",
      "X_train: (997079, 21) y_train: (997079,)\n",
      "X_val:   (213660, 21) y_val:   (213660,)\n",
      "X_test:  (213661, 21) y_test:  (213661,)\n",
      "X_train_seq: (997074, 5, 21) y_train_seq: (997074,)\n",
      "X_val_seq:   (213655, 5, 21) y_val_seq:   (213655,)\n",
      "X_test_seq:  (213656, 5, 21) y_test_seq:  (213656,)\n",
      "Epoch 1/2\n",
      "\u001B[1m 4051/31159\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:48\u001B[0m 8ms/step - loss: 0.0307"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
